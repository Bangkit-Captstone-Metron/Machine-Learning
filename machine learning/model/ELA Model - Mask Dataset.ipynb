{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ELA Model - Mask Dataset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOkkreCNrEuxlFDtc2isPi+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"tNNfg2kVx4GK","executionInfo":{"status":"ok","timestamp":1622563460657,"user_tz":-420,"elapsed":2964,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","\n","np.random.seed(2)\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from keras.optimizers import RMSprop\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from keras import optimizers\n","\n","sns.set(style='white', context='notebook', palette='deep')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPuhF0Kyykkq","executionInfo":{"status":"ok","timestamp":1622563460658,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}}},"source":["from PIL import Image\n","import os\n","from pylab import *\n","import re\n","from PIL import Image, ImageChops, ImageEnhance"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSt9HfTBybqB","executionInfo":{"status":"ok","timestamp":1622563581577,"user_tz":-420,"elapsed":120929,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"66ffe231-2630-4eed-bfb9-9ced9174f9ce"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LrCLaezOyoyN"},"source":["def convert_to_ela_image(path, quality):\n","    filename = path\n","    resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n","    ELA_filename = filename.split('.')[0] + '.ela.png'\n","    \n","    im = Image.open(filename).convert('RGB')\n","    im.save(resaved_filename, 'JPEG', quality=quality)\n","    resaved_im = Image.open(resaved_filename)\n","    \n","    ela_im = ImageChops.difference(im, resaved_im)\n","    \n","    extrema = ela_im.getextrema()\n","    max_diff = max([ex[1] for ex in extrema])\n","    if max_diff == 0:\n","        max_diff = 1\n","    scale = 255.0 / max_diff\n","    \n","    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n","    \n","    return ela_im"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2XAldyBydEE"},"source":["pristine_training_path = 'drive/MyDrive/image-forgery/training/pristine/'\n","fake_training_path = 'drive/MyDrive/image-forgery/training/fake/'\n","\n","saved_model_path = 'drive/MyDrive/Capstone Project/saved_models/'\n","pickle_path = 'drive/MyDrive/Capstone Project/pickle/ELA/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EhF9b8y15D1"},"source":["## Training Data Preparation"]},{"cell_type":"code","metadata":{"id":"cUvsDTtU2Dxo"},"source":["pristines = os.listdir(pristine_training_path)\n","pristines = list(filter(lambda x : 'resave' not in x, pristines))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfDHC-aK2HHC"},"source":["fakes = os.listdir(fake_training_path)[:-6]\n","fakes = list(filter(lambda x : 'resave' not in x and x != 'masks', fakes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4CxdQmN1OqD"},"source":["X_pristine = []\n","X_fake = []\n","\n","for pristine in pristines:\n","    X_pristine.append(array(convert_to_ela_image(pristine_training_path + pristine, 90).resize((128, 128))).flatten() / 255.0)\n","\n","with open(pickle_path + 'X_pristine.pickle', 'wb') as f:\n","    pickle.dump(X_pristine, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"boCt5y6EK16v"},"source":["for fake in fakes:\n","    X_fake.append(array(convert_to_ela_image(fake_training_path + fake, 90).resize((128, 128))).flatten() / 255.0)\n","\n","with open(pickle_path + 'X_fake.pickle', 'wb') as f:\n","    pickle.dump(X_fake, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSxIQl7jK4Bc"},"source":["X = X_pristine + X_fake\n","Y = [0] * len(X_pristine) + [1] * len(X_fake)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YZgHZEqm8c_Q"},"source":["## Normalization"]},{"cell_type":"code","metadata":{"id":"YXz-Gllm8fCO"},"source":["X = np.array(X)\n","Y = np.array(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_5O0sbU9kFl"},"source":["## Reshape"]},{"cell_type":"code","metadata":{"id":"e6NVxazM9lWV"},"source":["X = X.reshape(-1, 128, 128, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"at57ii0U9No8"},"source":["## Train-test Split"]},{"cell_type":"code","metadata":{"id":"Qt-jcjP_9Puh"},"source":["X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6LH8yQh9VGl"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"p7QGXyO79YHv"},"source":["model = Sequential()\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid', \n","                 activation ='relu', input_shape = (128,128,3)))\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid', \n","                 activation ='relu'))\n","\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = \"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation = \"sigmoid\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2LY5rA2-myR","executionInfo":{"status":"ok","timestamp":1622478149229,"user_tz":-420,"elapsed":23,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"4114278b-1331-444d-a628-98e52747ae8e"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 120, 120, 32)      25632     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 60, 60, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 60, 60, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 115200)            0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               29491456  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 29,519,777\n","Trainable params: 29,519,777\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEbP_kjN-p2_","executionInfo":{"status":"ok","timestamp":1622478149229,"user_tz":-420,"elapsed":13,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"b47d42c1-a76a-4133-c3da-9233d33079b5"},"source":["optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"pkhABkZM-tDH"},"source":["model.compile(optimizer = optimizer , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ybl-0Yse-vyb"},"source":["early_stopping = EarlyStopping(monitor='val_acc',\n","                              min_delta=0,\n","                              patience=2,\n","                              verbose=0, mode='auto')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8zBO55jD19Y","executionInfo":{"status":"ok","timestamp":1622478149230,"user_tz":-420,"elapsed":9,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"6d5f109c-9f1f-444d-c81e-31510914ab29"},"source":["Y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1200,)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"wdMquJJy-z11"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kmc0H7fz-0vs","executionInfo":{"status":"ok","timestamp":1622481311660,"user_tz":-420,"elapsed":3162436,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"71a0da00-2521-421c-cc23-34b06152a2b3"},"source":["epochs = 30\n","batch_size = 100\n","\n","model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, \n","          validation_data=(X_val, Y_val), verbose=1, callbacks=[early_stopping])\n","\n","model.save(saved_model_path + 'ela_model.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","12/12 [==============================] - 121s 9s/step - loss: 0.9336 - accuracy: 0.6014 - val_loss: 0.6275 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 2/30\n","12/12 [==============================] - 102s 9s/step - loss: 0.6091 - accuracy: 0.7226 - val_loss: 0.6241 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 3/30\n","12/12 [==============================] - 103s 9s/step - loss: 0.6079 - accuracy: 0.7051 - val_loss: 0.6219 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 4/30\n","12/12 [==============================] - 106s 9s/step - loss: 0.5931 - accuracy: 0.7015 - val_loss: 0.6292 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 5/30\n","12/12 [==============================] - 115s 10s/step - loss: 0.5999 - accuracy: 0.7029 - val_loss: 0.8843 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 6/30\n","12/12 [==============================] - 115s 10s/step - loss: 0.6411 - accuracy: 0.7253 - val_loss: 0.6159 - val_accuracy: 0.6700\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 7/30\n","12/12 [==============================] - 116s 10s/step - loss: 0.5492 - accuracy: 0.7345 - val_loss: 0.7109 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 8/30\n","12/12 [==============================] - 111s 9s/step - loss: 0.5513 - accuracy: 0.7268 - val_loss: 0.6751 - val_accuracy: 0.5667\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 9/30\n","12/12 [==============================] - 104s 9s/step - loss: 0.5576 - accuracy: 0.7422 - val_loss: 0.6211 - val_accuracy: 0.6767\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 10/30\n","12/12 [==============================] - 103s 9s/step - loss: 0.4928 - accuracy: 0.7629 - val_loss: 0.6304 - val_accuracy: 0.6600\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 11/30\n","12/12 [==============================] - 104s 9s/step - loss: 0.4818 - accuracy: 0.7785 - val_loss: 0.6498 - val_accuracy: 0.6567\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 12/30\n","12/12 [==============================] - 110s 9s/step - loss: 0.4697 - accuracy: 0.8013 - val_loss: 0.6871 - val_accuracy: 0.5633\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 13/30\n","12/12 [==============================] - 102s 8s/step - loss: 0.4527 - accuracy: 0.8137 - val_loss: 0.6289 - val_accuracy: 0.6533\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 14/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.3827 - accuracy: 0.8386 - val_loss: 0.6320 - val_accuracy: 0.6567\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 15/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.3741 - accuracy: 0.8356 - val_loss: 0.6763 - val_accuracy: 0.6100\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 16/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.3695 - accuracy: 0.8650 - val_loss: 0.7760 - val_accuracy: 0.6667\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 17/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.2803 - accuracy: 0.8858 - val_loss: 0.9421 - val_accuracy: 0.6633\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 18/30\n","12/12 [==============================] - 109s 9s/step - loss: 0.2934 - accuracy: 0.8802 - val_loss: 1.0104 - val_accuracy: 0.6667\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 19/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.2520 - accuracy: 0.9078 - val_loss: 0.8228 - val_accuracy: 0.6333\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 20/30\n","12/12 [==============================] - 101s 9s/step - loss: 0.2339 - accuracy: 0.9188 - val_loss: 0.8377 - val_accuracy: 0.6300\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 21/30\n","12/12 [==============================] - 103s 9s/step - loss: 0.2452 - accuracy: 0.9250 - val_loss: 0.9986 - val_accuracy: 0.6367\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 22/30\n","12/12 [==============================] - 102s 8s/step - loss: 0.1788 - accuracy: 0.9359 - val_loss: 0.8167 - val_accuracy: 0.5300\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 23/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.2694 - accuracy: 0.9239 - val_loss: 1.1355 - val_accuracy: 0.6167\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 24/30\n","12/12 [==============================] - 98s 8s/step - loss: 0.2660 - accuracy: 0.8982 - val_loss: 0.9302 - val_accuracy: 0.6233\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 25/30\n","12/12 [==============================] - 99s 8s/step - loss: 0.1461 - accuracy: 0.9585 - val_loss: 0.9357 - val_accuracy: 0.6000\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 26/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.1356 - accuracy: 0.9689 - val_loss: 0.8750 - val_accuracy: 0.6233\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 27/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.1110 - accuracy: 0.9799 - val_loss: 1.2397 - val_accuracy: 0.6333\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 28/30\n","12/12 [==============================] - 100s 8s/step - loss: 0.1285 - accuracy: 0.9678 - val_loss: 1.6288 - val_accuracy: 0.6300\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 29/30\n","12/12 [==============================] - 101s 8s/step - loss: 0.0897 - accuracy: 0.9765 - val_loss: 1.6837 - val_accuracy: 0.6433\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n","Epoch 30/30\n","12/12 [==============================] - 98s 8s/step - loss: 0.0885 - accuracy: 0.9735 - val_loss: 1.2859 - val_accuracy: 0.6267\n","WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOUxC96DbFSN","executionInfo":{"status":"ok","timestamp":1622481415546,"user_tz":-420,"elapsed":1006,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"65882d86-d6ca-41c2-c4c4-fde4e8d36ff9"},"source":["model.predict(X_val[:10])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.09785885],\n","       [0.94203883],\n","       [0.5718909 ],\n","       [0.98205626],\n","       [0.3356946 ],\n","       [0.6285888 ],\n","       [0.3540867 ],\n","       [0.29777113],\n","       [0.60776705],\n","       [0.20294803]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKH3Lb8RbVyA","executionInfo":{"status":"ok","timestamp":1622481420636,"user_tz":-420,"elapsed":311,"user":{"displayName":"Tony Eko Yuwono M0020108","photoUrl":"","userId":"08477086657466008291"}},"outputId":"6a9ccfd3-acf1-4755-a4df-db06fd03657d"},"source":["Y_val[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 0, 0, 0, 0, 1, 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":26}]}]}